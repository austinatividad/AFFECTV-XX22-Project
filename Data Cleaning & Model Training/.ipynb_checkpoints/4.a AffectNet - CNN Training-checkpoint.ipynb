{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0939ddf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Aaron\\anaconda3\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# !pip install librosa\n",
    "# !pip install lifelines\n",
    "# !pip install np_utils\n",
    "# !pip install tensorflow\n",
    "\n",
    "import librosa\n",
    "import librosa.display\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import sklearn\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import keras\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv1D, MaxPooling1D, Flatten, Dropout, BatchNormalization\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8028d1ad",
   "metadata": {},
   "source": [
    "## Importing and Splitting the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "525e9980",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the datasets\n",
    "train_set = pd.read_csv('./outputs/train_set_ov2.csv')\n",
    "test_set = pd.read_csv('./outputs/test_set_ov2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02ed3e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split into features and target; x = features, y = target\n",
    "x_train = train_set.iloc[:, 1:]\n",
    "y_train = train_set['label']\n",
    "\n",
    "x_test = test_set.iloc[:, 1:]\n",
    "y_test = test_set['label']\n",
    "\n",
    "#combining test and train set for cross validation\n",
    "x = pd.concat([x_train, x_test])\n",
    "y = pd.concat([y_train, y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9438e8ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lm_1_x</th>\n",
       "      <th>lm_1_y</th>\n",
       "      <th>lm_1_z</th>\n",
       "      <th>lm_2_x</th>\n",
       "      <th>lm_2_y</th>\n",
       "      <th>lm_2_z</th>\n",
       "      <th>lm_3_x</th>\n",
       "      <th>lm_3_y</th>\n",
       "      <th>lm_3_z</th>\n",
       "      <th>lm_4_x</th>\n",
       "      <th>...</th>\n",
       "      <th>lm_475_z</th>\n",
       "      <th>lm_476_x</th>\n",
       "      <th>lm_476_y</th>\n",
       "      <th>lm_476_z</th>\n",
       "      <th>lm_477_x</th>\n",
       "      <th>lm_477_y</th>\n",
       "      <th>lm_477_z</th>\n",
       "      <th>lm_478_x</th>\n",
       "      <th>lm_478_y</th>\n",
       "      <th>lm_478_z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.506702</td>\n",
       "      <td>0.746145</td>\n",
       "      <td>-0.052472</td>\n",
       "      <td>0.514746</td>\n",
       "      <td>0.638546</td>\n",
       "      <td>-0.127808</td>\n",
       "      <td>0.511097</td>\n",
       "      <td>0.660831</td>\n",
       "      <td>-0.061017</td>\n",
       "      <td>0.491482</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009648</td>\n",
       "      <td>0.642590</td>\n",
       "      <td>0.412839</td>\n",
       "      <td>0.009652</td>\n",
       "      <td>0.617289</td>\n",
       "      <td>0.435031</td>\n",
       "      <td>0.009619</td>\n",
       "      <td>0.642846</td>\n",
       "      <td>0.458015</td>\n",
       "      <td>0.009624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.473390</td>\n",
       "      <td>0.674256</td>\n",
       "      <td>-0.083987</td>\n",
       "      <td>0.458269</td>\n",
       "      <td>0.603338</td>\n",
       "      <td>-0.139770</td>\n",
       "      <td>0.468669</td>\n",
       "      <td>0.630927</td>\n",
       "      <td>-0.084655</td>\n",
       "      <td>0.449013</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016601</td>\n",
       "      <td>0.625927</td>\n",
       "      <td>0.450008</td>\n",
       "      <td>0.016597</td>\n",
       "      <td>0.602415</td>\n",
       "      <td>0.468034</td>\n",
       "      <td>0.016574</td>\n",
       "      <td>0.623425</td>\n",
       "      <td>0.487518</td>\n",
       "      <td>0.016578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.475091</td>\n",
       "      <td>0.712748</td>\n",
       "      <td>-0.064066</td>\n",
       "      <td>0.461303</td>\n",
       "      <td>0.598940</td>\n",
       "      <td>-0.138101</td>\n",
       "      <td>0.474313</td>\n",
       "      <td>0.626583</td>\n",
       "      <td>-0.068561</td>\n",
       "      <td>0.447728</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.030456</td>\n",
       "      <td>0.632130</td>\n",
       "      <td>0.402564</td>\n",
       "      <td>-0.030461</td>\n",
       "      <td>0.604959</td>\n",
       "      <td>0.423050</td>\n",
       "      <td>-0.030489</td>\n",
       "      <td>0.628164</td>\n",
       "      <td>0.448405</td>\n",
       "      <td>-0.030485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.493484</td>\n",
       "      <td>0.664245</td>\n",
       "      <td>-0.059163</td>\n",
       "      <td>0.471933</td>\n",
       "      <td>0.590218</td>\n",
       "      <td>-0.162500</td>\n",
       "      <td>0.486533</td>\n",
       "      <td>0.611204</td>\n",
       "      <td>-0.076221</td>\n",
       "      <td>0.453270</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002333</td>\n",
       "      <td>0.679121</td>\n",
       "      <td>0.346882</td>\n",
       "      <td>0.002329</td>\n",
       "      <td>0.642678</td>\n",
       "      <td>0.380518</td>\n",
       "      <td>0.002300</td>\n",
       "      <td>0.680462</td>\n",
       "      <td>0.413192</td>\n",
       "      <td>0.002304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.523146</td>\n",
       "      <td>0.650589</td>\n",
       "      <td>-0.062593</td>\n",
       "      <td>0.519441</td>\n",
       "      <td>0.581467</td>\n",
       "      <td>-0.126982</td>\n",
       "      <td>0.518384</td>\n",
       "      <td>0.603058</td>\n",
       "      <td>-0.068003</td>\n",
       "      <td>0.493491</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010894</td>\n",
       "      <td>0.615893</td>\n",
       "      <td>0.410073</td>\n",
       "      <td>0.010895</td>\n",
       "      <td>0.592702</td>\n",
       "      <td>0.431683</td>\n",
       "      <td>0.010865</td>\n",
       "      <td>0.617758</td>\n",
       "      <td>0.450027</td>\n",
       "      <td>0.010870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2710</th>\n",
       "      <td>0.510256</td>\n",
       "      <td>0.683243</td>\n",
       "      <td>-0.070947</td>\n",
       "      <td>0.516699</td>\n",
       "      <td>0.595183</td>\n",
       "      <td>-0.144286</td>\n",
       "      <td>0.514165</td>\n",
       "      <td>0.620626</td>\n",
       "      <td>-0.072752</td>\n",
       "      <td>0.490072</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015552</td>\n",
       "      <td>0.642479</td>\n",
       "      <td>0.379912</td>\n",
       "      <td>0.015555</td>\n",
       "      <td>0.614993</td>\n",
       "      <td>0.404506</td>\n",
       "      <td>0.015520</td>\n",
       "      <td>0.643303</td>\n",
       "      <td>0.428452</td>\n",
       "      <td>0.015526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2711</th>\n",
       "      <td>0.505334</td>\n",
       "      <td>0.686409</td>\n",
       "      <td>-0.058882</td>\n",
       "      <td>0.508532</td>\n",
       "      <td>0.599290</td>\n",
       "      <td>-0.122200</td>\n",
       "      <td>0.509442</td>\n",
       "      <td>0.622162</td>\n",
       "      <td>-0.062568</td>\n",
       "      <td>0.491475</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011714</td>\n",
       "      <td>0.641445</td>\n",
       "      <td>0.401308</td>\n",
       "      <td>0.011715</td>\n",
       "      <td>0.616812</td>\n",
       "      <td>0.420869</td>\n",
       "      <td>0.011687</td>\n",
       "      <td>0.638138</td>\n",
       "      <td>0.443780</td>\n",
       "      <td>0.011692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2712</th>\n",
       "      <td>0.478502</td>\n",
       "      <td>0.704455</td>\n",
       "      <td>-0.054058</td>\n",
       "      <td>0.466725</td>\n",
       "      <td>0.630798</td>\n",
       "      <td>-0.111903</td>\n",
       "      <td>0.480140</td>\n",
       "      <td>0.650520</td>\n",
       "      <td>-0.051867</td>\n",
       "      <td>0.451859</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000233</td>\n",
       "      <td>0.622744</td>\n",
       "      <td>0.435086</td>\n",
       "      <td>-0.000233</td>\n",
       "      <td>0.593390</td>\n",
       "      <td>0.463393</td>\n",
       "      <td>-0.000256</td>\n",
       "      <td>0.623990</td>\n",
       "      <td>0.490850</td>\n",
       "      <td>-0.000254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2713</th>\n",
       "      <td>0.535946</td>\n",
       "      <td>0.839739</td>\n",
       "      <td>-0.009758</td>\n",
       "      <td>0.533225</td>\n",
       "      <td>0.735975</td>\n",
       "      <td>-0.171670</td>\n",
       "      <td>0.536654</td>\n",
       "      <td>0.754226</td>\n",
       "      <td>-0.058587</td>\n",
       "      <td>0.508789</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.075247</td>\n",
       "      <td>0.767251</td>\n",
       "      <td>0.377080</td>\n",
       "      <td>-0.075249</td>\n",
       "      <td>0.724138</td>\n",
       "      <td>0.410647</td>\n",
       "      <td>-0.075284</td>\n",
       "      <td>0.763825</td>\n",
       "      <td>0.447404</td>\n",
       "      <td>-0.075284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2714</th>\n",
       "      <td>0.496285</td>\n",
       "      <td>0.695451</td>\n",
       "      <td>-0.058970</td>\n",
       "      <td>0.496497</td>\n",
       "      <td>0.621925</td>\n",
       "      <td>-0.120260</td>\n",
       "      <td>0.495928</td>\n",
       "      <td>0.643076</td>\n",
       "      <td>-0.062304</td>\n",
       "      <td>0.478978</td>\n",
       "      <td>...</td>\n",
       "      <td>0.021327</td>\n",
       "      <td>0.619558</td>\n",
       "      <td>0.444905</td>\n",
       "      <td>0.021330</td>\n",
       "      <td>0.595854</td>\n",
       "      <td>0.466720</td>\n",
       "      <td>0.021301</td>\n",
       "      <td>0.620156</td>\n",
       "      <td>0.487816</td>\n",
       "      <td>0.021307</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2715 rows Ã— 1434 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        lm_1_x    lm_1_y    lm_1_z    lm_2_x    lm_2_y    lm_2_z    lm_3_x  \\\n",
       "0     0.506702  0.746145 -0.052472  0.514746  0.638546 -0.127808  0.511097   \n",
       "1     0.473390  0.674256 -0.083987  0.458269  0.603338 -0.139770  0.468669   \n",
       "2     0.475091  0.712748 -0.064066  0.461303  0.598940 -0.138101  0.474313   \n",
       "3     0.493484  0.664245 -0.059163  0.471933  0.590218 -0.162500  0.486533   \n",
       "4     0.523146  0.650589 -0.062593  0.519441  0.581467 -0.126982  0.518384   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "2710  0.510256  0.683243 -0.070947  0.516699  0.595183 -0.144286  0.514165   \n",
       "2711  0.505334  0.686409 -0.058882  0.508532  0.599290 -0.122200  0.509442   \n",
       "2712  0.478502  0.704455 -0.054058  0.466725  0.630798 -0.111903  0.480140   \n",
       "2713  0.535946  0.839739 -0.009758  0.533225  0.735975 -0.171670  0.536654   \n",
       "2714  0.496285  0.695451 -0.058970  0.496497  0.621925 -0.120260  0.495928   \n",
       "\n",
       "        lm_3_y    lm_3_z    lm_4_x  ...  lm_475_z  lm_476_x  lm_476_y  \\\n",
       "0     0.660831 -0.061017  0.491482  ...  0.009648  0.642590  0.412839   \n",
       "1     0.630927 -0.084655  0.449013  ...  0.016601  0.625927  0.450008   \n",
       "2     0.626583 -0.068561  0.447728  ... -0.030456  0.632130  0.402564   \n",
       "3     0.611204 -0.076221  0.453270  ...  0.002333  0.679121  0.346882   \n",
       "4     0.603058 -0.068003  0.493491  ...  0.010894  0.615893  0.410073   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "2710  0.620626 -0.072752  0.490072  ...  0.015552  0.642479  0.379912   \n",
       "2711  0.622162 -0.062568  0.491475  ...  0.011714  0.641445  0.401308   \n",
       "2712  0.650520 -0.051867  0.451859  ... -0.000233  0.622744  0.435086   \n",
       "2713  0.754226 -0.058587  0.508789  ... -0.075247  0.767251  0.377080   \n",
       "2714  0.643076 -0.062304  0.478978  ...  0.021327  0.619558  0.444905   \n",
       "\n",
       "      lm_476_z  lm_477_x  lm_477_y  lm_477_z  lm_478_x  lm_478_y  lm_478_z  \n",
       "0     0.009652  0.617289  0.435031  0.009619  0.642846  0.458015  0.009624  \n",
       "1     0.016597  0.602415  0.468034  0.016574  0.623425  0.487518  0.016578  \n",
       "2    -0.030461  0.604959  0.423050 -0.030489  0.628164  0.448405 -0.030485  \n",
       "3     0.002329  0.642678  0.380518  0.002300  0.680462  0.413192  0.002304  \n",
       "4     0.010895  0.592702  0.431683  0.010865  0.617758  0.450027  0.010870  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "2710  0.015555  0.614993  0.404506  0.015520  0.643303  0.428452  0.015526  \n",
       "2711  0.011715  0.616812  0.420869  0.011687  0.638138  0.443780  0.011692  \n",
       "2712 -0.000233  0.593390  0.463393 -0.000256  0.623990  0.490850 -0.000254  \n",
       "2713 -0.075249  0.724138  0.410647 -0.075284  0.763825  0.447404 -0.075284  \n",
       "2714  0.021330  0.595854  0.466720  0.021301  0.620156  0.487816  0.021307  \n",
       "\n",
       "[2715 rows x 1434 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7913b4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Get the labels\n",
    "encoder = OneHotEncoder()\n",
    "y_train = encoder.fit_transform(np.array(y_train).reshape(-1,1)).toarray()\n",
    "y_test = encoder.fit_transform(np.array(y_test).reshape(-1,1)).toarray()\n",
    "\n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "228f2d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test)\n",
    "# x_train.shape, y_train.shape, x_test.shape, y_test.shape\n",
    "\n",
    "x_train = np.expand_dims(x_train, axis=2)\n",
    "x_test = np.expand_dims(x_test, axis=2)\n",
    "# x_train.shape, y_train.shape, x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "86f45f48",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10861, 1434, 1), (10861, 4), (2715, 1434, 1), (2715, 4))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, y_train.shape, x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d28fc8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Aaron\\anaconda3\\lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Aaron\\anaconda3\\lib\\site-packages\\keras\\src\\backend.py:6642: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Aaron\\anaconda3\\lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 1434, 256)         1536      \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1  (None, 717, 256)          0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 717, 256)          327936    \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPoolin  (None, 359, 256)          0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 359, 256)          327936    \n",
      "                                                                 \n",
      " max_pooling1d_2 (MaxPoolin  (None, 180, 256)          0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 180, 256)          0         \n",
      "                                                                 \n",
      " conv1d_3 (Conv1D)           (None, 180, 256)          327936    \n",
      "                                                                 \n",
      " max_pooling1d_3 (MaxPoolin  (None, 90, 256)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 23040)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32)                737312    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 4)                 132       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1722788 (6.57 MB)\n",
      "Trainable params: 1722788 (6.57 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model= Sequential()\n",
    "model.add(Conv1D(256, kernel_size=5, strides=1, padding='same', activation='relu', input_shape=(x_train.shape[1], 1)))\n",
    "model.add(MaxPooling1D(pool_size=5, strides = 2, padding = 'same'))\n",
    "\n",
    "model.add(Conv1D(256, kernel_size=5, strides=1, padding='same', activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=5, strides = 2, padding = 'same'))\n",
    "\n",
    "model.add(Conv1D(256, kernel_size=5, strides=1, padding='same', activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=5, strides = 2, padding = 'same'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv1D(256, kernel_size=5, strides=1, padding='same', activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=5, strides = 2, padding = 'same'))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=32, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(units=4, activation='softmax'))\n",
    "model.compile(optimizer = 'adam' , loss = 'categorical_crossentropy' , metrics = ['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "967196a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Aaron\\\\Desktop\\\\Github Projects\\\\AFFECT\\\\AFFECTV-XX22-Project-revised-oversampling/ckpt_cnn/Epoch{epoch:02d}_{val_accuracy:.2f}.keras'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_filepath = os.getcwd() + '/ckpt_cnn/Epoch{epoch:02d}_{val_accuracy:.2f}.keras'\n",
    "checkpoint_filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "163a0cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc1e5c8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "WARNING:tensorflow:From C:\\Users\\Aaron\\anaconda3\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Aaron\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "170/170 [==============================] - 76s 441ms/step - loss: 1.2346 - accuracy: 0.4344 - val_loss: 0.9503 - val_accuracy: 0.6866 - lr: 0.0010\n",
      "Epoch 2/30\n",
      "170/170 [==============================] - 75s 440ms/step - loss: 1.0939 - accuracy: 0.5179 - val_loss: 0.7829 - val_accuracy: 0.7532 - lr: 0.0010\n",
      "Epoch 3/30\n",
      "170/170 [==============================] - 75s 440ms/step - loss: 1.0409 - accuracy: 0.5416 - val_loss: 0.7392 - val_accuracy: 0.7282 - lr: 0.0010\n",
      "Epoch 4/30\n",
      " 20/170 [==>...........................] - ETA: 1:02 - loss: 0.9928 - accuracy: 0.5680"
     ]
    }
   ],
   "source": [
    "rlrp = ReduceLROnPlateau(monitor='val_accuracy', factor=0.8, verbose=1, patience=2, min_lr=0.0001)\n",
    "history = model.fit(x_train, y_train, batch_size=64, epochs=30, validation_data=(x_test, y_test), callbacks=[rlrp, model_checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d5e578",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = [i for i in range(30)]\n",
    "fig, ax = plt.subplots(1,2)\n",
    "train_accuracy = history.history['accuracy']\n",
    "train_loss = history.history['loss']\n",
    "test_accuracy = history.history['val_accuracy']\n",
    "test_loss = history.history['val_loss']\n",
    "\n",
    "fig.set_size_inches(20,6)\n",
    "ax[0].plot(epochs, train_loss, label = 'Training Loss')\n",
    "ax[0].plot(epochs, test_loss, label = 'Validation Loss')\n",
    "ax[0].set_title('Training & Validation Loss Over Epochs')\n",
    "ax[0].legend()\n",
    "ax[0].set_xlabel(\"Epochs\")\n",
    "\n",
    "ax[1].plot(epochs, train_accuracy, label = 'Training Accuracy')\n",
    "ax[1].plot(epochs, test_accuracy, label = 'Validation Accuracy')\n",
    "ax[1].set_title('Training & Validation Accuracy Over Epochs')\n",
    "ax[1].legend()\n",
    "ax[1].set_xlabel(\"Epochs\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5efbc5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test = model.predict(x_test)\n",
    "y_pred = encoder.inverse_transform(pred_test)\n",
    "y_test = encoder.inverse_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7ab1a4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize = (12, 10))\n",
    "cm = pd.DataFrame(cm , index = [i for i in encoder.categories_] , columns = [i for i in encoder.categories_])\n",
    "sns.heatmap(cm, linecolor='white', cmap='Blues', linewidth=1, annot=True, fmt='')\n",
    "plt.title('Confusion Matrix', size=20)\n",
    "plt.xlabel('Predicted Labels', size=14)\n",
    "plt.ylabel('Actual Labels', size=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e83466",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "acs_test = accuracy_score(y_test,y_pred)\n",
    "ps_test = precision_score(y_test,y_pred, average = \"macro\")\n",
    "rs_test = recall_score(y_test,y_pred,  average = \"macro\")\n",
    "fs_test = f1_score(y_test,y_pred,  average = \"macro\")\n",
    "\n",
    "print(\"Accuracy Score: \", \"{:.2%}\".format(acs_test))\n",
    "print(\"Precision Score: \", \"{:.2%}\".format(ps_test))\n",
    "print(\"Recall Score: \", \"{:.2%}\".format(rs_test))\n",
    "print(\"F1 Score: \", \"{:.2%}\".format(fs_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26222ffb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
